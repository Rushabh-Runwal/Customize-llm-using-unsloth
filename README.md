# üß† Customize LLMs using Unsloth

This repository contains my solutions to the **LLM Finetuning Assignment** using [Unsloth](https://unsloth.ai), exploring multiple use cases like finetuning, continued pretraining, chat templates, reward modeling, and deployment with Ollama.  
Each section is backed by working Colab notebooks and recorded videos explaining the process, dataset, input formats, and expected outputs.

> üìå **Submission Deadline:** March 20, 2025

---

## üìÅ Repository Structure

- ‚úÖ Finetuning with open-weight LLMs (4 use cases)
- ‚úÖ Continued Pretraining with a new language
- ‚úÖ Chat Templates (classification, conversation, extended context)
- ‚úÖ Reward Modeling (DPO + ORPO)
- ‚úÖ Continued Finetuning from Checkpoints
- ‚úÖ Mental Health Chatbot Finetuning
- ‚úÖ Ollama Export and Inference

---

## üß™ Use Cases and Colabs

| Task | Description | Notebook Link |
|------|-------------|----------------|
| **(a)** Finetuning on different use cases with chat model templates | Coding, Chat, etc. using Llama, Mistral, Gemma, Phi models | [Colab 1](https://colab.research.google.com/drive/1Be29emJ3Ph1Kyl2ELtHvGTzw8_lR0xl2?usp=sharing) |
| **(b)** Continued Pretraining | Make LLM learn a new language | [Colab 2](https://colab.research.google.com/drive/1l9e_YDKDQTpGcriCG0IJb2XMoYNkF46a?usp=sharing) |
| **(c)** Chat Templates | For classification, conversational chat, context extension | [Colab 3](https://colab.research.google.com/drive/1erICOGQmhFr30Y_3k29O0HKzICjl6MCn?usp=sharing) |
| **(d)** Reward Modeling | With ORPO and DPO | [Colab 4](https://colab.research.google.com/drive/1hAJ8XwcXvuAXLuub9jZKEST-ZzsX_MbS?usp=sharing) |
| **(e)** Continued Fine-Tuning from Custom Checkpoint | Resume training from saved checkpoints | [Colab 5](https://colab.research.google.com/drive/1HYIaPu5zg7N9p51RTw6xcHS9qhIJrPe4?usp=sharing) |
| **(f)** Finetune for Mental Health Chatbot | Based on Microsoft Phi-3 | [Colab 6](https://colab.research.google.com/drive/13ozUQeKyHCQ3xYM3eD0z0sAQEcZXlt82?usp=sharing) |
| **(g)** Ollama Export + Inference | Finetune and run model via Ollama | [Colab 7](https://colab.research.google.com/drive/1HsXWAlliPRHFKuPmIHwDuEVIv402L6zF?usp=sharing) |

---

## üìπ [Video Walkthroughs](www.youtube.com)

Each notebook is accompanied by a recorded video walkthrough where I explain:
- The architecture used
- Dataset preparation
- Input format and prompt engineering
- Finetuning logic
- Evaluation or inference
- Any challenges faced and how they were resolved

---

## üîó Helpful Resources & References

- [Unsloth Docs](https://docs.unsloth.ai)
- [Unsloth LoRA + Ollama Guide](https://sarinsuriyakoon.medium.com/unsloth-lora-with-ollama-lightweight-solution-to-full-cycle-llm-development-edadb6d9e0f0)
- [Mental Health Chatbot Fine-tuning](https://medium.com/@mauryaanoop3/fine-tuning-microsoft-phi3-with-unsloth-for-mental-health-chatbot-development-ddea4e0c46e7)

---

## üì¨ Contact

Created with üí° by [Rushabh Runwal](https://github.com/Rushabh-Runwal)  
If you found this useful, feel free to ‚≠ê the repo!
